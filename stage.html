<!DOCTYPE html>
<html>
<head>
<title>GIP website J. Swaelen</title>
<link rel="icon" type="image" href="img/favicon.ico" />
<script src="script.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Bangers|Oxygen" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/pure/0.6.0/pure-min.css">
<link rel="stylesheet" href="balloon.css">
<link rel="stylesheet" href="main.css">
<script src="https://use.fontawesome.com/8b162ad928.js"></script>
</head>

<body>
<header>
	<h1 id="headerGip-Text" class="headerEffect">GIP website <div id="profielFoto" data-balloon="Welkom!" data-balloon-pos="left"></div>Jelle Swaelen</h1>
</header>
    
<div class="pure-g middenGip">
	<div class="pure-u-1-3 middenGip-menu">
        <p><a href=index.html>HOME</a></p>
	</div>
    <div class="pure-u-1-3 middenGip-menu-selected">
        <p><a>STAGE</a></p>
	</div>
	<div class="pure-u-1-3 middenGip-menu">
        <p><a href=taken.html>INFO</a></p>
	</div>
</div>

<div class="pure-g middenGip">
    <div class="pure-u-1 middenGip-1">
		<h1>Huisstijl stagebedrijf</h1>
        <p><b>Minimalistisch en zeer functioneel</b><br>Ik heb mijn stage mogen doen bij Wappla, ze hebben een neutrale stijl die ook net toont en dat merk je bijvoorbeeld in de kantoorruimte. Alles is er ordelijk en er zijn geen meubelen in flashy kleuren.<br><br><b>Meest gebruikte kleuren: zilver, wit, zwart en blauw</b><br></p>
        <table class="pure-table">
            <thead>
                <tr>
                    <th style="background-color:#CCC"></th>
                    <th style="background-color:#FFF"></th>
                    <th style="background-color:#000"></th>
                    <th style="background-color:#6D9EEB"></th>
                </tr>
            </thead>
        </table>
        <p><b>Logo</b></p>
        <img src="img/logo-wappla.png"/>
        <p><b>Gebruikte fonts (Signika en Open Sans)</b><br>Deze fonts vind ik zelf ook wel mooi en ze zien er zeker minimalistisch en duidelijk uit.<br><br><b>Huisstijl eigen website</b><br>Bij mijn eigen website heb ik ook geprobeerd een minimalistische stijl te behouden. Persoonlijk denk ik wel dat ik daarin ben geslaagd, maar ik zou graag nog veranderingen maken aan de weergave van de info-pagina. Sinds er doorheen het tweede semester heel wat nieuwe dingen gaan bijkomen, zal de verticale stijl van weergeven zoals het nu is, niet meer zo overzichtelijk zijn.</p>
	</div>

    <div id="vergrootVerklein15" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
        <h1><i class="fa fa-arrow-down" aria-hidden="true"></i> Reportage photos du stage chez Wappla <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
                <iframe class="pure-u-1" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" height="500" width="1000" src="https://prezi.com/embed/dz-fyaogwoib/?bgcolor=ffffff&amp;lock_to_path=1&amp;autoplay=0&amp;autohide_ctrls=0&amp;landing_data=bHVZZmNaNDBIWnNjdEVENDRhZDFNZGNIUE43MHdLNWpsdFJLb2ZHanI0U2hvREhQMXFGTTczTkxRcFhOelBPYnp3PT0&amp;landing_sign=EyFYituJ7DFevOeiNa65Z5SfhjWUCvIv1-1ldkRKDA4"></iframe>
    </div>

    <div id="vergrootVerklein14" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
        <h1><i class="fa fa-arrow-down" aria-hidden="true"></i> Review of a software tool <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>A review of Amazon Web Services</b><br>Amazon Web Services is a service provided by Amazon, that gives you the possibility to store tons of files in the cloud. It is made to provide you with a server where you can store all your backup files as a safeguard for when your web server fails or somehow loses files. My internship company mostly uses this service to store their backup files. I found this review published on pcmag.com, which I do find a reliable source. Not only do they publish news around the latest technology, they also write reviews about most newly released products and software.<br><br>The review I read is written by Steven J. Vaughan-Nichols and can be found <b><a href="http://www.pcmag.com/article2/0,2817,2496299,00.asp">here.</a></b><br><i>I didn’t copy the review below my personal review, because it’s fairly long and didn’t look good as it uses images and videos between paragraphs.</i><br><br><b>What about the competition?</b><br>Amazon isn’t the only one providing this service. Other companies like Microsoft and Google have very similar services for cloud storage, Microsoft has Azure and Google has Google Cloud Platform. All of these have different pros and cons depending on what you’re going to use it for. One of the things they all have largely in common is the use of the tool and all three services are remotely accessible. Depending on how much storage you need you might be better off using Google Cloud Platform, because in comparison with the other services that only give you 1TB of storage, Google can provide you with up to 10TB. But in general the use of these tools is quite simple. You remotely connect to the server that’s given to you and configure it the way you want it. During the internship my task was based around Amazon Web Services as I needed to make a script that would backup all files of a certain web server and then back them up to the AWS server.<br><br><b>Is it any good?</b><br>Something the review states, is that it’s highly customizable. That is because they offer lots of associated services and because you’re able to build your own things with management tools and custom coded apps. This however does mean that if you’re going to manage your AWS yourself, you’ll need to educate yourself a bit on how to do certain things. All of this was great in my opinion, it does require more time if you’re not familiar with AWS, but also gives you more variations in terms of how you can complete.<br><br><b>Do I recommend it?</b><br>Personally I liked using the tool, since it has great and easy to use features. It took some time for me to understand the functionalities, but in the end I was always able to do what I had planned. Of course I didn’t get to use or try all the functionalities because there are so many, but the ones I did use were easy to understand and worked flawlessly. I recommend Amazon Web Services to anyone, not just businesses, who needs to have lots of files stored safely.</p>
    </div>

    <div class="pure-u-1 middenGip-1">
        <h1>Stageverslagen</h1>
    </div>
    <div id="vergrootVerklein4" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
		<h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-16 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
		<p><b>Uitleg over algemene taak:</b><br>Soort script schrijven dat elke dag van de webpagina samen met de database een backup maakt. Hosting gebeurt op Plesk en de backup zou opgeslagen moeten worden op Amazon S3.<br><br><b>Geïnstalleerde tools hiervoor:</b><br>Putty, dit is het programma dat je een console geeft waarmee je aanpassingen kan maken op je Plesk host.<br><br><b>AWS Command Line Interface (CLI) geïnstalleerd en een gebruiker geconfigureerd:</b><br>Gebruikte tool => Putty.<br><br><b>Informatie opgezocht over de mogelijke manieren om een backup te maken van alle website documenten</b></p>
	</div>
    <div id="vergrootVerklein5" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
		<h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-17 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Verder gezocht naar een oplossing voor de code.</b><br><br><i>Niet alles kan in één keer gedaan worden, zoals de code hierboven. Om de backup te verplaatsen van de SSH en dan door te sturen naar de AWS cloud, moet er met meerdere stappen gewerkt worden.</i><br><br><b>1) Zippen van de mappen met essentiële bestanden en exporteren van database op de host.</b><br><br>http-bestanden:<br><code>tar -zcv sitebackup_blockpress.io_"datum".tar.gz /var/www/vhosts/blockpress.io/httpdocs</code><br><br>database:<br>[NIETS VOOR GEVONDEN VANDAAG]<br><br><b>2) Het gezipte bestand van de host naar de desktop van de lokale computer sturen.</b><br><br>http-bestanden:<br><code>pscp jelle@jelle.wappla.com:/var/www/_backups/sitebackup_blockpress.io_2017-01-16.tar %USERPROFILE%\Desktop</code><br><br>database:<br><code>pscp jelle@jelle.wappla.com:/var/www/_backups/naamBackup.sql %USERPROFILE%\Desktop</code><br><br><b>3) De database en het gezipte bestand met alle http bestanden uploaden naar de AWS.</b><br><br>http-bestanden:<br><code>aws s3 cp sitebackup_blockpress.io_”datum”.tar s3://wappla-jelle-backups</code><br><br>database:<br><code>aws s3 cp wordpress_e.sql s3://wappla-jelle-backups</code></p>
	</div>
    <div id="vergrootVerklein6" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
		<h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-18 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Oplossing voor exporteren database gevonden:</b><br><br><i>Fout wachtwoord en username gebruikt, juiste naam en password gevonden in:<br>blockpress.io/httpdocs/wp-config.php => Op het server web paneel</i><br><br><b>USERNAME:</b> root => wordpress_2 (Database username)<br><b>PASSWORD:</b> ww123 => Bijhorend password<br><br><b>Werkende code die de database exporteert naar de backup map:</b><br><code>mysqldump -u wordpress_2 -p"password" wordpress_e > /var/www/_backups/db_backup_”datum”.sql</code><br><br>Verder zoeken naar een manier om van alle apart werkende code één geheel te maken:<br><br>Maken van een script dat uitgevoerd kan worden op de Linux server.<br><br><i><b>scriptNaam.sh => Naam van een script-file op Linux</b><br>! => Execute rechten aanpassen zodat iedereen het kan uitvoeren.</i><br><br><i><b>chmod 755 fileName => Hiermee geef je iedereen rechten het bestand uit te voeren en te lezen en geef je de eigenaar ook rechten het bestand te veranderen.</b><br>Bestand aanmaken kan simpelweg met “touch test.sh”</i><br><br><b>Parameters:</b> DomainName, UserName, UserPassword en dbName<br><br><b>Code om de datum van vandaag in een variabele te krijgen en af te printen:</b><br><code>CurrentDate=$(date +%D)<br>echo “$CurrentDate”</code><br><i><b>=> Bv.: 01/18/17</b> notatie is dus: MM/DD/YY<br><br><b>UPDATE: 2017-01-20 Deze notatie zorgde voor fouten, “/” verandert in “-”.</b></i><br><code>CurrentDate=$(date +%Y-%m-%d)</code><i><br><b>=> Bv.: 01-20-2017</b> notatie is nu: MM-DD-YYYY</i></p>
	</div>
    <div id="vergrootVerklein7" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
		<h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-19 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Debugging script:</b><br><br><code>zip -r backup_blockpress.io_2017-01-19.zip /var/www/vhosts/blockpress.io/httpdocs/</code><br><b>=> Werkt als het apart op de command line wordt ingegeven, niet in script.</b><br><br><code>!#/bin/bash<br><br>DomainName=$1<br>zip -r /var/www/_backups/backup_${DomainName}_datum.zip /var/www/vhosts/${DomainName}/httpdocs/</code><br>=> Wanneer de variabele van de datum niet wordt meegegeven aan de naam van het gezipt bestand, werkt het script.<br><br><code>!#/bin/bash<br><br>DomainName=$1<br>dbUserName=$2<br>dbPassword=$3<br>dbName=$4<br>zip -r /var/www/_backups/backup_${DomainName}_datum.zip /var/www/vhosts/${DomainName}/httpdocs/<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/_backups/db_backup_datum.sql</code><br>=><i> Als een variabele deel uitmaakt van een string, gebruik je: ${naamVar}, enkel de waarde van de variabele zonder links/rechts tekst toe te voegen: $naamVar</i><br><br><b>=> Nog steeds geen variabele met de datum van de dag die kan worden meegegeven, maar het exporteren van de database met de variabelen werkt.</b></p>
	</div>
    <div id="vergrootVerklein8" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
        <h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-20 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>AWS S3 geïnstalleerd en geconfigureerd op SSH server. (Enkel op user)</b><br><br>Om alle “buckets” weer te geven: <i>./aws s3 ls</i><br><br><code>!#/bin/bash<br><br>DomainName=$1<br>dbUserName=$2<br>dbPassword=$3<br>dbName=$4<br>BucketName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br>zip -r /var/www/_backups/backup_${DomainName}_${CurrentDate}.zip/var/www/vhosts/${DomainName}/httpdocs/<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/_backups/db_backup_${CurrentDate}.sql<br>/root/bin/aws s3 cp /var/www/_backups/backup_${DomainName}_${CurrentDate}.zip s3://wappla-jelle-backups<br>/root/bin/aws s3 cp /var/www/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}<br></code><b>Bovenstaand script werkt =><i> Mijn fout was dat ik als datum notatie .../.../… gebruikte, in Linux wordt “/” gebruikt om een pad mee te geven wat zorgde voor fouten.</i></b><br><br>Alle bestanden en onderliggende mappen in “httpdocs” worden correct gezipt en de database wordt ook op de juiste manier geëxporteerd. Beide bestanden worden daarna geüpload naar de juiste bucket.</p>
	</div>
    
    <div id="vergrootVerklein9" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
        <h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-23 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Zoeken naar een manier om het script elke dag automatisch te laten uitvoeren.</b><br><br>Uitvoeren werkt, enkel nog juiste rechten geven aan de gebruiker die het commando uitvoert of eventueel een manier vinden om aanmelden als root mogelijk te maken.<br><br><b>Zippen en exporteren database werkt, uploaden naar aws nog niet.</b><br><i>Bestanden werden gezipt naar een map waar de gebruiker geen rechten had, map verandert en het werkt. (zie code onderaan)</i><br><br><b>Pad naar aws werkte niet, pad verandert naar => /usr/local/aws/bin/aws</b><br><i>(zie vetgedrukt onderaan)<br><b>Locatie backup-script.sh is ook aangepast!</b></i><br><br><code>#!/bin/bash<br><br>DomainName=$1<br>dbUserName=$2<br>dbPassword=$3<br>dbName=$4<br>BucketName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br>zip -r /var/www/vhosts/blockpress.io/_backups/backup_${DomainName}_${CurrentDate}.zip /var/www/vhosts/${DomainName}/httpdocs/<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/vhosts/blockpress.io/_backups/db_backup_${CurrentDate}.sql<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/blockpress.io/_backups/backup_${DomainName}_${CurrentDate}.zip s3://${BucketName}<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/blockpress.io/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}</code><br><br><b>“Scheduled task” laten uitvoeren. Hier geef ik een commando mee dat het script zal uitvoeren, aan dit commando geef ik ook alle parameters mee.</b><br><br><i><b>Update 2017-01-25</b> Commando:<br></i><code>/var/www/vhosts/backup-script.sh blockpress.io wappla-jelle-backups wordpress_2 f5SyA82#Tb wordpress_e</code></p>
	</div>
    <div id="vergrootVerklein10" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
		<h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-24 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Onderstaande foutmelding opgelost door aan te melden op de user die het script automatisch uitvoert en daar de credentials in te vullen.</b><br><code>upload failed: _backups/backup_blockpress.io_2017-01-24.zip to s3://wappla-jelle-backups/backup_blockpress.io_2017-01-24.zip Unable to locate credentials<br>upload failed: _backups/db_backup_2017-01-24.sql to s3://wappla-jelle-backups/db_backup_2017-01-24.sql Unable to locate credentials</code><br><br><b>De httpdocs folder wordt goed gezipt, de database wordt ook goed geëxporteerd en beide bestanden worden geüpload naar AWS. De enige foutmelding die er nu op komt is:</b><br><i>/var/www/vhosts/blockpress.io/backup-script.sh: line 1: !#/bin/bash: No such file or directory<br><b>!Typfout => !#/bin/bash moet #!/bin/bash zijn</b></i><br><br>Nieuwe opdracht: gebruiksaanwijzingen schrijven voor het script en ervoor zorgen dat de bestanden van een bepaald domein in de juiste map terechtkomen en met de juiste datum.<br><br><b>Code toegevoegd die een beter georganiseerde folder structuur geeft binnen de bucket met de naam van het domein en een subfolder in deze map met de datum waarop de backup is gemaakt.</b><br><br><code>#!/bin/bash<br>DomainName=$1<br>dbUserName=$2<br>dbPassword=$3<br>dbName=$4<br>BucketName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br>zip -r /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip /var/www/vhosts/${DomainName}/httpdocs/<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}/${DomainName}/backup_${CurrentDate}/</code><br><br><b>Handleiding script:</b><br><br>Ten eerste zorgt het script ervoor dat de <b>locatie</b> van de <b>config- en credentials-files</b> wordt aangepast zodat alle users ze kunnen lezen. <b>Wat je dus best eerst kan doen is de credentials ingeven zodat deze files bestaan:</b><br><br><code>$ aws configure<br>AWS Access Key ID [None]: foo<br>AWS Secret Access Key [None]: bar<br>Default region name [None]: eu-test-1<br>Default output format [None]: ...</code>Dit <b>voer</b> je ook best <b>uit als user</b>, op die manier hebben de accounts van de andere subscriptions ook de rechten om de locatie van de nodige bestanden te veranderen en ze te lezen.<br><br>Dan wordt er, als er nog geen is, een subfolder <i>“_backups”</i> gemaakt in de folder met de <b>domeinnaam</b> (/var/www/vhosts/<i>Domeinnaam</i>).<br><br>Daarna wordt ervoor gezorgd dat de <b>httpdocs-folder</b> (/var/www/vhosts/<i>Domeinnaam</i>/httpdocs/) gezipt word en de bijbehorende database geëxporteerd wordt. Als dat gedaan is gaat het de backup bestanden <b>uploaden naar AWS</b>. In de meegegeven bucket zal het script dan een folder maken met als naam de opgegeven domeinnaam, daarin zal nog een subfolder aangemaakt worden met de datum waarop de backup is geüpload.<br><br>Ten slotte zal het script <b>controleren</b> of de database en het zip bestand geüpload zijn. Wanneer de bestanden zich op de AWS bevinden, wordt de locatie weergegeven, als dit niet het geval is krijg je een melding dat de bestanden zich niet op de AWS bevinden.<br><br>Dit zijn de parameters van het script:<br>1) De <b>domeinnaam (verplicht)</b>, bv.: blockpress.io<br>2) De <b>naam</b> van de <b>bucket (verplicht)</b> waarnaar de backup-bestanden worden geüpload, bv.: domain-backupfiles<br>3) De <b>database username (optioneel)</b>, bv.: dbUser-blockpress.io<br>4) Het <b>wachtwoord</b> van deze <b>database user (optioneel)</b>, bv.: www123<br>5) De <b>naam</b> van de <b>database (optioneel)</b>, bv.: db-blockpress.io<br><br><b>Voorbeeld:</b><br><br><code>/var/www/vhosts/backup-script.sh blockpress.io domain-backups dbUser-blockpress.io www123 db-blockpress.io</code><br>Bovenstaande code geef je in als commando voor een geautomatiseerde taak bij Plesk, wat je kan vinden onder:<br><b>Subscriptions => domeinnaam.com => Scheduled Tasks => Add Task => “Task type: Run a command” => Command</b><br><i><a href="https://drive.google.com/file/d/0ByrojiqCZfnodzhOY1dSS2hJUG8/view?usp=sharing">Er is ook een markdown versie van de handleiding.</a></i><br><br><b>Huisstijl stagebedrijf onderzocht en enkele dingen opgesomd in het document.</b><br><b>Begin geschreven van de review over AWS.</b><br><br>Nieuwe opdracht: Mogelijk maken dat er geen database wordt meegegeven en bepaalde dingen uitzoeken over AWS CLI zodat er niet voor elke subscription AWS moet worden geïnstalleerd.<br><br><b>Volgorde parameters aangepast zodat de eerste twee parameters altijd dezelfde zijn.<br>If-functie toevoegen zodat het mogelijk is geen database mee te geven.</b><br><br><code>#!/bin/bash<br>DomainName=$1<br>BucketName=$2<br>dbUserName=$3<br>dbPassword=$4<br>dbName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br><br>if ! [ ${dbUserName} == "" ]; then mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql;<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}/${DomainName}/backup_${CurrentDate}/;<br>fi<br>zip -r /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip /var/www/vhosts/${DomainName}/httpdocs/<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip s3://${BucketName}/${DomainName}/backup_${CurrentDate}/</code><br><i>Werkt nog niet, exporteert en upload nog steeds de database (maar dan wel leeg) ook al wordt er geen naam, username en password meegegeven.</i></p>
	</div>
    <div id="vergrootVerklein11" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
		<h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-25 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Ervoor zorgen dat de if-functie werkt.</b><br><br><code>#!/bin/bash<br>DomainName=$1<br>BucketName=$2<br>dbUserName=$3<br>dbPassword=$4<br>dbName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br><br>if [[ -n ${dbUserName} || -n ${dbPassword} || -n ${dbName} ]]<br>then<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br>fi<br><br>zip -r /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip /var/www/vhosts/${DomainName}/httpdocs/<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br></code><br><br>If statement aangepast zodat enkel de database wordt geëxporteerd wanneer de database gebruikersnaam, het bijhorende wachtwoord en de database naam wordt meegegeven.<br><i>=> Wanneer dit niet wordt meegegeven gaat het script alleen de httpdocs-folder zippen en uploaden.</i><br><br><b>Mogelijkheid toevoegen die ervoor zorgt dat de folder “_backups” wordt aangemaakt als subfolder van de folder met de domeinnaam.</b><br><br><code>#!/bin/bash<br><br>DomainName=$1<br>BucketName=$2<br>dbUserName=$3<br>dbPassword=$4<br>dbName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br><br>mkdir -p /var/www/vhosts/${DomainName}/_backups<br><br>if [[ -n ${dbUserName} || -n ${dbPassword} || -n ${dbName} ]]<br>then<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br>fi<br><br>zip -r /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip /var/www/vhosts/${DomainName}/httpdocs/<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br></code><i>Zorgt ervoor dat wanneer de folder nog niet bestaat, er een wordt aangemaakt.</i><br><br><b>Onderzoeken hoe de AWS CLI best geconfigureerd kan worden op andere “subscriptions”:</b><br><i>Locatie van de config- en credentials-file aangepast zodat users er aan kunnen.<br>!Pad naar deze files moet dan ook wel aangepast worden:</i><br><br><code>export AWS_SHARED_CREDENTIALS_FILE=/path/to/shared_credentials_file<br>export AWS_CONFIG_FILE=/path/to/config_file</code><br><i>Wanneer bovenstaande regels worden ingegeven, kan elke nieuwe user het script gebruiken. Regels toegevoegd aan script, zodat dit nu ook geautomatiseerd is.</i><br><br><code>#!/bin/bash<br>DomainName=$1<br>BucketName=$2<br>dbUserName=$3<br>dbPassword=$4<br>dbName=$5<br>CurrentDate=$(date +%Y-%m-%d)<br><br>export AWS_SHARED_CREDENTIALS_FILE=/path/to/shared_credentials_file<br>export AWS_CONFIG_FILE=/path/to/config_file<br><br>mkdir -p /var/www/vhosts/${DomainName}/_backups<br><br>if [[ -n ${dbUserName} || -n ${dbPassword} || -n ${dbName} ]]<br>then<br>mysqldump -u $dbUserName -p${dbPassword} $dbName > /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br>fi<br><br>zip -r /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip /var/www/vhosts/${DomainName}/httpdocs/<br>/usr/local/aws/bin/aws s3 cp /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip s3://${BucketName}/${DomainName}/backup_${CurrentDate}/<br></code></p>
	</div>
    <div id="vergrootVerklein12" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
        <h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-26 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Script uitbreiden zodat als de backup-files geüpload zijn, ze automatisch verwijdert worden op de host.</b><br><br>If-functie toegevoegd die nakijkt of de backup-files op de AWS staan en ze lokaal verwijdert als ze online staan.<br>Wanneer er een database is meegegeven wordt die ook lokaal verwijdert, nadat hij online staat.<br><br><code>path=s3://${BucketName}/${DomainName}/backup_${CurrentDate}/backup_${DomainName}_${CurrentDate}.zip<br>count=$(aws s3 ls $path | wc -l)<br>if [ $count -gt 0 ]<br>then<br>echo -e "\n$path\nThe line above shows where your backup files are located on AWS.\nIf you also had a database, you'll be able to find the export on that location too."<br>rm -f /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip<br>if [[ -n ${dbUserName} || -n ${dbPassword} || -n ${dbName} ]]<br>then<br>rm -f /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql<br>fi<br>else<br>echo -e "Unfortunately your files have not been uploaded."<br>fi</code></p>
	</div>
    <div id="vergrootVerklein13" onclick="vergrootVerklein(this.id)" class="pure-u-1 middenGip-1-4-taak">
        <h1><i class="fa fa-arrow-down" aria-hidden="true"></i> 2017-01-27 <i class="fa fa-arrow-down" aria-hidden="true"></i></h1>
        <p><b>Aparte controles toevoegen die elk nakijken of de database en het gezipte bestand is geüpload.</b><br><br><code>pathZip=s3://${BucketName}/${DomainName}/backup_${CurrentDate}/backup_${DomainName}_${CurrentDate}.zip<br>pathDB=s3://${BucketName}/${DomainName}/backup_${CurrentDate}/db_backup_${CurrentDate}.sql<br><br>countZip=$(/usr/local/aws/bin/aws s3 ls $pathZip | wc -l)<br>countDB=$(/usr/local/aws/bin/aws s3 ls $pathDB | wc -l)<br><br>if [ $countZip -gt 0 ]<br>then<br>echo -e "\n$pathZip\nThe line above shows where your backup file is located on AWS."<br>rm -f /var/www/vhosts/${DomainName}/_backups/backup_${DomainName}_${CurrentDate}.zip<br>else<br>echo -e "Unfortunately, your zipped file has not been uploaded."<br>fi<br><br>if [[ -n ${dbUserName} || -n ${dbPassword} || -n ${dbName} ]]<br>then<br>if [ $countDB -gt 0 ]<br>then<br>echo -e "\n$pathDB\nThe line above shows where your database backup is located on AWS."<br>rm -f /var/www/vhosts/${DomainName}/_backups/db_backup_${CurrentDate}.sql<br>else<br>echo -e "Unfortunately, your database backup has not been uploaded."<br>fi<br>fi</code><br><br><b>Handleiding uitbreiden en <a target="_blank" href="https://drive.google.com/open?id=0ByrojiqCZfnodzhOY1dSS2hJUG8">script</a> en <a target="_blank" href="https://drive.google.com/file/d/0ByrojiqCZfnoVnR6Vllic0M3S2s/view?usp=sharing">README</a> delen.</b></p>
	</div>
</div>
    
<footer id="footerGip">
	<p id="footerGip-Text">GIP website&nbsp;2016</p>
</footer>
</body>
</html>
